// ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
// PostgreSQL ã‚¹ã‚­ãƒ¼ãƒé©ç”¨ã¨ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†

const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');

// ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
require('dotenv').config();

class DatabaseMigrator {
  constructor() {
    // ğŸ” ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š
    if (!process.env.DATABASE_URL) {
      throw new Error('DATABASE_URL environment variable is required');
    }

    this.pool = new Pool({
      connectionString: process.env.DATABASE_URL,
      ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
      max: 20, // æœ€å¤§æ¥ç¶šæ•°åˆ¶é™
      idleTimeoutMillis: 30000, // ã‚¢ã‚¤ãƒ‰ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
      connectionTimeoutMillis: 2000, // æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    });

    // è¨±å¯ã•ã‚ŒãŸSQLæ“ä½œã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆ
    this.allowedStatements = [
      'CREATE TABLE',
      'CREATE INDEX',
      'CREATE UNIQUE INDEX',
      'CREATE EXTENSION',
      'ALTER TABLE',
      'INSERT INTO',
      'COMMENT ON',
      'DO $$', // PLpgSQL blocks
    ];
  }

  // ğŸ” SQLã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®å®‰å…¨ãªè§£æ
  parseSqlStatements(sql) {
    try {
      // ã‚³ãƒ¡ãƒ³ãƒˆã¨ç©ºè¡Œã‚’é™¤å»
      const cleanedSql = sql
        .replace(/--.*$/gm, '') // è¡Œã‚³ãƒ¡ãƒ³ãƒˆé™¤å»
        .replace(/\/\*[\s\S]*?\*\//g, '') // ãƒ–ãƒ­ãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆé™¤å»
        .replace(/^\s*\n/gm, ''); // ç©ºè¡Œé™¤å»

      // ã‚»ãƒŸã‚³ãƒ­ãƒ³ã§åˆ†å‰²ã—ã€ç©ºæ–‡ã§ãªã„ã‚‚ã®ã‚’è¿”ã™
      return cleanedSql
        .split(';')
        .map(stmt => stmt.trim())
        .filter(stmt => stmt.length > 5); // æœ€å°æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        
    } catch (error) {
      console.error('âŒ SQL parsing failed:', error);
      throw new Error('Failed to parse SQL statements');
    }
  }

  // ğŸ” SQLã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®å®‰å…¨æ€§æ¤œè¨¼
  isValidStatement(statement) {
    const upperStatement = statement.toUpperCase();
    
    // å±é™ºãªã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–
    const dangerousPatterns = [
      'DROP DATABASE',
      'DROP SCHEMA',
      'TRUNCATE',
      'DELETE FROM',
      'UPDATE SET',
      'GRANT ALL',
      'REVOKE',
      'CREATE USER',
      'CREATE ROLE',
      'ALTER USER',
      'ALTER ROLE'
    ];

    for (const pattern of dangerousPatterns) {
      if (upperStatement.includes(pattern)) {
        console.warn(`âš ï¸ Blocked dangerous statement: ${pattern}`);
        return false;
      }
    }

    // è¨±å¯ã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
    const isAllowed = this.allowedStatements.some(allowed => 
      upperStatement.startsWith(allowed)
    );

    if (!isAllowed) {
      console.warn(`âš ï¸ Statement not in whitelist: ${statement.substring(0, 50)}...`);
      return false;
    }

    return true;
  }

  async runMigrations() {
    console.log('ğŸš€ Starting database migration...');
    
    try {
      // æ¥ç¶šãƒ†ã‚¹ãƒˆ
      await this.testConnection();
      
      // ãƒ¡ã‚¤ãƒ³ã‚¹ã‚­ãƒ¼ãƒé©ç”¨
      await this.applySchema();
      
      // è¿½åŠ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
      await this.runAdditionalMigrations();
      
      // åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
      await this.seedInitialData();
      
      console.log('âœ… Database migration completed successfully!');
      
    } catch (error) {
      console.error('ğŸ’¥ Migration failed:', error);
      throw error;
    } finally {
      await this.pool.end();
    }
  }

  async testConnection() {
    console.log('ğŸ”Œ Testing database connection...');
    
    const client = await this.pool.connect();
    try {
      const result = await client.query('SELECT NOW() as current_time, version() as pg_version');
      console.log(`âœ… Connected to PostgreSQL at ${result.rows[0].current_time}`);
      console.log(`ğŸ“Š PostgreSQL version: ${result.rows[0].pg_version.split(',')[0]}`);
    } finally {
      client.release();
    }
  }

  async applySchema() {
    console.log('ğŸ“‹ Applying main schema...');
    
    const schemaPath = path.join(__dirname, 'schema.sql');
    const schemaSql = fs.readFileSync(schemaPath, 'utf8');
    
    const client = await this.pool.connect();
    try {
      await client.query('BEGIN');
      
      // ğŸ” ã‚»ã‚­ãƒ¥ã‚¢ãªSQLã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆå®Ÿè¡Œ
      const statements = this.parseSqlStatements(schemaSql);
      
      let executedCount = 0;
      for (const statement of statements) {
        if (this.isValidStatement(statement)) {
          try {
            await client.query(statement);
            executedCount++;
            console.log(`âœ… Executed statement ${executedCount}/${statements.length}`);
          } catch (error) {
            console.error(`âŒ Failed to execute statement: ${statement.substring(0, 100)}...`);
            throw error;
          }
        } else {
          console.warn(`âš ï¸ Skipped potentially unsafe statement: ${statement.substring(0, 50)}...`);
        }
      }
      
      await client.query('COMMIT');
      console.log('âœ… Main schema applied successfully');
      
    } catch (error) {
      await client.query('ROLLBACK');
      console.error('âŒ Schema application failed:', error);
      throw error;
    } finally {
      client.release();
    }
  }

  async runAdditionalMigrations() {
    console.log('ğŸ”„ Running additional migrations...');
    
    const migrationsDir = path.join(__dirname, 'migrations');
    
    if (!fs.existsSync(migrationsDir)) {
      console.log('ğŸ“‚ No migrations directory found, skipping...');
      return;
    }
    
    const migrationFiles = fs.readdirSync(migrationsDir)
      .filter(file => file.endsWith('.sql'))
      .sort();
    
    if (migrationFiles.length === 0) {
      console.log('ğŸ“ No migration files found, skipping...');
      return;
    }
    
    const client = await this.pool.connect();
    try {
      // ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
      await client.query(`
        CREATE TABLE IF NOT EXISTS schema_migrations (
          id SERIAL PRIMARY KEY,
          filename VARCHAR(255) UNIQUE NOT NULL,
          applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
      `);
      
      // å®Ÿè¡Œæ¸ˆã¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—
      const appliedResult = await client.query(
        'SELECT filename FROM schema_migrations ORDER BY applied_at'
      );
      const appliedMigrations = appliedResult.rows.map(row => row.filename);
      
      // æœªå®Ÿè¡Œã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
      for (const filename of migrationFiles) {
        if (appliedMigrations.includes(filename)) {
          console.log(`â­ï¸ Skipping already applied migration: ${filename}`);
          continue;
        }
        
        console.log(`ğŸ”„ Applying migration: ${filename}`);
        
        const migrationPath = path.join(migrationsDir, filename);
        const migrationSql = fs.readFileSync(migrationPath, 'utf8');
        
        await client.query('BEGIN');
        try {
          await client.query(migrationSql);
          await client.query(
            'INSERT INTO schema_migrations (filename) VALUES ($1)',
            [filename]
          );
          await client.query('COMMIT');
          
          console.log(`âœ… Applied migration: ${filename}`);
        } catch (error) {
          await client.query('ROLLBACK');
          console.error(`âŒ Failed to apply migration ${filename}:`, error);
          throw error;
        }
      }
      
    } finally {
      client.release();
    }
  }

  async seedInitialData() {
    console.log('ğŸŒ± Seeding initial data...');
    
    const client = await this.pool.connect();
    try {
      // ç®¡ç†è€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª
      const adminCheck = await client.query(
        'SELECT COUNT(*) as count FROM admins'
      );
      
      if (parseInt(adminCheck.rows[0].count) === 0) {
        console.log('ğŸ‘¤ Creating default admin account...');
        
        const bcrypt = require('bcrypt');
        
        // ğŸ” ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèªè¨¼æƒ…å ±
        const adminEmail = process.env.ADMIN_DEFAULT_EMAIL || 'admin@localhost';
        const defaultPassword = process.env.ADMIN_DEFAULT_PASSWORD;
        
        if (!defaultPassword) {
          // æœ¬ç•ªç’°å¢ƒã§ã¯å¿…ãšç’°å¢ƒå¤‰æ•°ã§æŒ‡å®šã™ã‚‹ã“ã¨ã‚’å¼·åˆ¶
          if (process.env.NODE_ENV === 'production') {
            throw new Error('âš ï¸ ADMIN_DEFAULT_PASSWORD environment variable is required in production');
          }
          
          // é–‹ç™ºç’°å¢ƒã§ã¯å®‰å…¨ãªãƒ©ãƒ³ãƒ€ãƒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
          const crypto = require('crypto');
          const generatedPassword = crypto.randomBytes(16).toString('base64');
          console.log(`ğŸ” Generated secure password: ${generatedPassword}`);
          console.log('âš ï¸ Please save this password - it will not be shown again!');
          
          const passwordHash = await bcrypt.hash(generatedPassword, 12); // ã‚ˆã‚Šå¼·ã„ãƒãƒƒã‚·ãƒ¥
          
          await client.query(`
            INSERT INTO admins (email, password_hash, created_at, is_active)
            VALUES ($1, $2, CURRENT_TIMESTAMP, true)
          `, [adminEmail, passwordHash]);
          
          console.log(`âœ… Default admin created - Email: ${adminEmail}`);
          console.log(`ğŸ” Password: ${generatedPassword}`);
        } else {
          // ç’°å¢ƒå¤‰æ•°ã§æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
          if (defaultPassword.length < 8) {
            throw new Error('âš ï¸ ADMIN_DEFAULT_PASSWORD must be at least 8 characters long');
          }
          
          const passwordHash = await bcrypt.hash(defaultPassword, 12);
          
          await client.query(`
            INSERT INTO admins (email, password_hash, created_at, is_active)
            VALUES ($1, $2, CURRENT_TIMESTAMP, true)
          `, [adminEmail, passwordHash]);
          
          console.log(`âœ… Default admin created - Email: ${adminEmail}`);
          console.log('ğŸ” Using password from ADMIN_DEFAULT_PASSWORD environment variable');
        }
      } else {
        console.log('ğŸ‘¤ Admin accounts already exist, skipping creation');
      }
      
      // ãƒ†ãƒ¼ãƒ–ãƒ«çŠ¶æ…‹ã‚µãƒãƒªãƒ¼
      const tables = ['admins', 'ada_requests', 'ada_presigned', 'ada_txs', 'audit_logs', 'admin_sessions'];
      
      console.log('\nğŸ“Š Database Summary:');
      for (const table of tables) {
        try {
          const result = await client.query(`SELECT COUNT(*) as count FROM ${table}`);
          console.log(`  ${table}: ${result.rows[0].count} records`);
        } catch (error) {
          console.log(`  ${table}: Table not found or error`);
        }
      }
      
    } finally {
      client.release();
    }
  }

  async resetDatabase() {
    // ğŸ” æœ¬ç•ªç’°å¢ƒã§ã®åˆ¶é™
    if (process.env.NODE_ENV === 'production') {
      throw new Error('âš ï¸ Database reset is not allowed in production environment');
    }

    console.log('ğŸ—‘ï¸ Resetting database...');
    console.warn('âš ï¸ This will permanently delete all data!');
    
    const client = await this.pool.connect();
    try {
      await client.query('BEGIN');
      
      // ğŸ” ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ï¼ˆSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰
      const dropTables = [
        'audit_logs',
        'admin_sessions', 
        'ada_txs',
        'ada_presigned',
        'ada_requests',
        'admins',
        'schema_migrations'
      ];
      
      // ãƒ†ãƒ¼ãƒ–ãƒ«åã®æ¤œè¨¼
      const validTableNames = dropTables.filter(table => 
        /^[a-zA-Z_][a-zA-Z0-9_]*$/.test(table) && table.length < 64
      );
      
      if (validTableNames.length !== dropTables.length) {
        throw new Error('Invalid table names detected');
      }
      
      for (const table of validTableNames) {
        // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã¯ä½¿ãˆãªã„ãŸã‚ã€äº‹å‰æ¤œè¨¼æ¸ˆã¿ã®å®‰å…¨ãªãƒ†ãƒ¼ãƒ–ãƒ«åã®ã¿ä½¿ç”¨
        await client.query(`DROP TABLE IF EXISTS "${table}" CASCADE`);
        console.log(`ğŸ—‘ï¸ Dropped table: ${table}`);
      }
      
      // æ‹¡å¼µå‰Šé™¤
      await client.query('DROP EXTENSION IF EXISTS "uuid-ossp"');
      
      // ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å‰Šé™¤
      const sequences = await client.query(`
        SELECT sequence_name 
        FROM information_schema.sequences 
        WHERE sequence_schema = 'public'
      `);
      
      for (const seq of sequences.rows) {
        if (/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(seq.sequence_name)) {
          await client.query(`DROP SEQUENCE IF EXISTS "${seq.sequence_name}" CASCADE`);
          console.log(`ğŸ—‘ï¸ Dropped sequence: ${seq.sequence_name}`);
        }
      }
      
      await client.query('COMMIT');
      console.log('âœ… Database reset completed');
      
    } catch (error) {
      await client.query('ROLLBACK');
      console.error('âŒ Database reset failed:', error);
      throw error;
    } finally {
      client.release();
    }
  }
}

// CLIå®Ÿè¡Œ
async function main() {
  const args = process.argv.slice(2);
  const command = args[0] || 'migrate';
  
  const migrator = new DatabaseMigrator();
  
  try {
    switch (command) {
      case 'migrate':
        await migrator.runMigrations();
        break;
      case 'reset':
        await migrator.resetDatabase();
        await migrator.runMigrations();
        break;
      case 'reset-only':
        await migrator.resetDatabase();
        break;
      default:
        console.log('Usage: node migrate.js [migrate|reset|reset-only]');
        process.exit(1);
    }
  } catch (error) {
    console.error('ğŸ’¥ Database operation failed:', error);
    process.exit(1);
  }
}

// ç›´æ¥å®Ÿè¡Œæ™‚
if (require.main === module) {
  main();
}

module.exports = { DatabaseMigrator };